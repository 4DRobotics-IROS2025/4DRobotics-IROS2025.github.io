<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>4D Scene Understanding for Intelligent Robotics - IROS 2025 Workshop</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <script src="https://kit.fontawesome.com/a076d05399.js" crossorigin="anonymous"></script>
</head>

<body>
    <div class="container">
        <header>
            <h1>4D Scene Understanding for Intelligent Robotics</h1>
            <h2>Advancements for Intelligent Robotics in 4D Scenes:<br>Localization, Reconstruction, Rendering, and
                Generation</h2>
            <p class="workshop-info">IROS 2025 Workshop</p>
            <div class="nav-container">
                <nav>
                    <ul>
                        <li><a href="#about">About</a></li>
                        <li><a href="#organizers">Organizers</a></li>
                        <li><a href="#speakers">Speakers</a></li>
                        <li><a href="#schedule">Schedule</a></li>
                        <li><a href="#call">Call for Papers</a></li>
                        <li><a href="#dates">Important Dates</a></li>
                    </ul>
                </nav>
            </div>
        </header>

        <section id="about">
            <h2>About the Workshop</h2>
            <p>Modern robotic systems must operate safely and robustly in dynamic environments.
                Conventional methods for tracking, mapping, grasping, view synthesis, and scene understanding often
                struggle when assumptions about scene stability are violated. This workshop explores the challenges and
                solutions of <strong>4D robotics</strong>—spatial perception enhanced by temporal context—by exploring
                the interplay of dynamic localization, real-time reconstruction, high-fidelity rendering, and generative
                modeling. We aim to identify and standardize benchmarks, discuss novel evaluation protocols, and inspire
                cross-disciplinary collaborations. Through engaging keynotes and paper presentations, participants will
                gain insights into state-of-the-art approaches and chart future research directions for next-generation
                robotics.</p>
        </section>

        <section id="organizers">
            <h2>Organizers</h2>
            <div class="organizers-grid">
                <a href="https://yanyan-li.github.io/">
                    <div class="organizer">
                        <img src="images/yanyan.png" alt="Yanyan Li" class="profile-img">
                        <h3>Yanyan Li</h3>
                        <p>National University of Singapore</p>
                    </div>
                </a>
                <a href="https://lixin.ai/">
                    <div class="organizer">
                        <img src="images/XinLi.png" alt="Xin Li" class="profile-img">
                        <h3>Xin Li</h3>
                        <p>Nanyang Technological University</p>
                    </div>
                </a>
                <a href="https://shangbuhuan13.github.io/">
                    <div class="organizer">
                        <img src="images/YanDi.png" alt="Yan Di" class="profile-img">
                        <h3>Yan Di</h3>
                        <p>Technology University of Munich<br>Harbin Institute of Technology</p>
                    </div>
                </a>
                <a href="https://lolrudy.github.io/">
                    <div class="organizer">
                        <img src="images/rudy.jpg" alt="Ruida Zhang" class="profile-img">
                        <h3>Ruida Zhang</h3>
                        <p>Tsinghua University</p>
                    </div>
                </a>
                <a href="https://xiangyueliu.github.io/">
                    <div class="organizer">
                        <img src="images/Xiangyue.jpg" alt="Xiangyue Liu" class="profile-img">
                        <h3>Xiangyue Liu</h3>
                        <p>Hong Kong University of Science and Technology</p>
                    </div>
                </a>
                <a href="https://wangyida.github.io/">
                    <div class="organizer">
                        <img src="images/YidaWang_CAMP.png" alt="Yida Wang" class="profile-img">
                        <h3>Yida Wang</h3>
                        <p>Li Auto</p>
                    </div>
                </a>
                <a href="https://www.cs.cit.tum.de/en/camp/members/zhongliang-jiang/">
                    <div class="organizer">
                        <img src="images/zhongliang.jpg" alt="Zhongliang Jiang" class="profile-img">
                        <h3>Zhongliang Jiang</h3>
                        <p>Technology University of Munich</p>
                    </div>
                </a>
                <a href="https://blogs.ntu.edu.sg/chau-yuen/">
                    <div class="organizer">
                        <img src="images/Chau.jpg" alt="Chau Yuen" class="profile-img">
                        <h3>Chau Yuen</h3>
                        <p>Nanyang Technological University</p>
                    </div>
                </a>
            </div>
            <p class="contact-info"><strong>Contact:</strong> yanyan.li.camp@gmail.com; xin019@e.ntu.edu.sg</p>
        </section>

        <section id="speakers">
            <h2>Invited Speakers</h2>
            <div class="speakers-grid">
                <!-- <a href="#">
                    <div class="speaker">
                        <img src="images/placeholder.svg" alt="Gim Hee Lee" class="profile-img">
                        <h3>Prof. Gim Hee Lee</h3>
                        <p>National University of Singapore</p>
                        <p><strong>Status: Confirmed</strong></p>
                        <p><strong>Topic:</strong> High-fidelity View Synthesis and Scene Understanding</p>
                    </div>
                </a>
                <a href="#">
                    <div class="speaker">
                        <img src="images/placeholder.svg" alt="Danping Zou" class="profile-img">
                        <h3>Prof. Danping Zou</h3>
                        <p>Shanghai Jiaotong University</p>
                        <p><strong>Status: TBD</strong></p>
                        <p><strong>Topic:</strong> Real-time Localization in Dynamic Scenes</p>
                    </div>
                </a>
                <a href="#">
                    <div class="speaker">
                        <img src="images/placeholder.svg" alt="Federico Tombari" class="profile-img">
                        <h3>Prof. Federico Tombari</h3>
                        <p>Technical University of Munich, Google</p>
                        <p><strong>Status: Confirmed</strong></p>
                        <p><strong>Topic:</strong> 4D Scene Interaction and Generation</p>
                    </div>
                </a>
                <a href="#">
                    <div class="speaker">
                        <img src="images/placeholder.svg" alt="Xiaozhi Chen" class="profile-img">
                        <h3>Dr. Xiaozhi Chen</h3>
                        <p>DJI</p>
                        <p><strong>Status: TBD</strong></p>
                        <p><strong>Topic:</strong> Next Generation of Perception in Autonomous Driving</p>
                    </div>
                </a> -->
                <a href="#">
                    <div class="speaker">
                        <img src="images/placeholder.svg" alt="Additional Speaker" class="profile-img">
                        <h3>Speaker</h3>
                        <p>TBD</p>
                    </div>
                </a>
            </div>
            <p><em>We are also engaging additional speakers from diverse geographical regions and underrepresented
                    groups to ensure a broad set of perspectives.</em></p>
        </section>

        <section id="schedule">
            <h2>Tentative Schedule</h2>
            <div class="schedule-container">
                <table class="schedule-table">
                    <thead>
                        <tr>
                            <th>Time</th>
                            <th>Activity</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>8:30 - 8:40</td>
                            <td>Welcome and Opening Remarks</td>
                        </tr>
                        <tr>
                            <td>8:40 - 9:10</td>
                            <td>
                                <strong>Keynote 1:</strong> (TBD)<br>
                                <!-- <em>Focus: Latest breakthroughs in temporal mapping and localization</em>
                                <strong>Keynote 1:</strong> Emerging Trends in 4D Scene Understanding<br>
                                <em>Focus: Latest breakthroughs in temporal mapping and localization</em> -->
                            </td>
                        </tr>
                        <tr>
                            <td>9:10 - 9:40</td>
                            <td>
                                <strong>Keynote 2:</strong> (TBD)<br>
                                <!-- <em>Focus: Techniques for achieving high-speed, temporally coherent rendering</em> -->
                            </td>
                        </tr>
                        <tr>
                            <td>9:40 - 10:30</td>
                            <td>Coffee break at posters (Posters of workshop papers and invited conference
                                papers)</td>
                        </tr>
                        <tr>
                            <td>10:30 - 11:00</td>
                            <td>
                                <strong>Keynote 3:</strong> (TBD)<br>
                                <!-- <em>Focus: Frontier research on visual language models and open vocabulary tasks</em> -->
                            </td>
                        </tr>
                        <tr>
                            <td>11:00 - 11:30</td>
                            <td>
                                <strong>Keynote 4:</strong> (TBD)<br>
                                <!-- <em>Focus: Techniques for achieving high-speed autonomous driving</em> -->
                            </td>
                        </tr>
                        <tr>
                            <td>11:30 - 12:20</td>
                            <td><strong>Oral Paper Presentations:</strong> Selected contributions on dynamic 4D methods
                            </td>
                        </tr>
                        <tr>
                            <td>12:20 - 12:30</td>
                            <td>Paper Award Announcement and Closing Remarks</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </section>

        <section id="call">
            <h2>Call for Papers</h2>
            <p>Submissions are <em>non-archival</em>, allowing previously accepted or ongoing work to be presented
                (accepted papers will be made available on our workshop website). Three categories of papers are
                welcomed:</p>
            <ul>
                <li><strong>Full Papers:</strong> Up to 8 pages (excluding references and appendix, i.e., 8+n pages)
                </li>
                <li><strong>Short Papers:</strong> Up to 4 pages (excluding references and appendix, i.e., 4+n pages)
                </li>
                <li><strong>Extended Abstracts:</strong> Up to 2 pages (excluding references and appendix, i.e., 2+n
                    pages)</li>
            </ul>
            <p>We will conduct a <strong>double-blind review</strong> with at least two expert reviewers per paper.
                Submissions will be judged on relevance, technical merit, clarity, and potential impact.
                <strong>Outstanding papers</strong> will be invited for extended submissions to a special journal issue
                (TBD). Two <strong>Best Paper Awards</strong> (oral and poster) are planned to recognize outstanding
                papers and encourage high-quality contributions.</p>
        </section>

        <section id="dates">
            <h2>Important Dates(Tentative)</h2>
            <div class="dates-container">
                <table class="dates-table">
                    <thead>
                        <tr>
                            <th>Event</th>
                            <th>Date</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Submission Opens</td>
                            <td>08 Jul, 2025</td>
                        </tr>
                        <tr>
                            <td>Submission Deadline</td>
                            <td>20 Sep, 2025 (AoE)</td>
                        </tr>
                        <tr>
                            <td>Notification of Acceptance</td>
                            <td>30 Sep, 2025</td>
                        </tr>
                        <tr>
                            <td>Camera-Ready Deadline</td>
                            <td>10 Oct, 2025</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </section>

        <footer>
            <p>&copy; 2025 4D Scene Understanding for Intelligent Robotics Workshop</p>
            <p>Website: <a href="https://4drobotics-iros2025.github.io/">https://4drobotics-iros2025.github.io/</a></p>
        </footer>
    </div>
</body>

</html>